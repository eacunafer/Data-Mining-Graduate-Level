{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMP 6315 \n",
    "\n",
    "### Feature Selection en Clasificacion Supervisada\n",
    "#### Edgar Acuna\n",
    "\n",
    "Uso de feature_selection de scikit-learn, del modulo feature selection de Arizona State University, del modulo skrebate para feature selection y del modulo Orange.\n",
    "\n",
    "### I-Usando la prueba de Chi-Square para ver si hay independencia entre la feature y la clase.\n",
    "\n",
    "De preferencia los datos deben estar discretizados y ademas con dos clases es mejor\n",
    "\n",
    "Personalmente no la recomiendo porque la priueba de Chisquare es aproximada y no muy robusta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chi-Square usando el  modulo de Feature selction de Scikit-learn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as m\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, SelectPercentile, f_classif, mutual_info_classif\n",
    "# load data\n",
    "url= \"http://academic.uprm.edu/eacuna/diabetes.dat\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "data = pd.read_table(url, names=names,header=None)\n",
    "y=data['class']\n",
    "X=data.iloc[:,0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion auxiliar para discretizar cualquier columna de un dataframe\n",
    "def disc_col_ew(df,str,k,out):\n",
    "    df1=df[str]\n",
    "    bins=np.linspace(df1.min(), df1.max(),k)\n",
    "    if out==\"num\":\n",
    "        df1=pd.cut(df1,bins=bins,include_lowest=True, right=True,labels=False)\n",
    "    else:\n",
    "        bins[0]=float('-inf')\n",
    "        bins[k-1]=float('inf')\n",
    "        df1=pd.cut(df1,bins=bins,include_lowest=True, right=True)  \n",
    "    return df1\n",
    "# funcion auxiliar para determinar el numero optimo de intervalos segun la formula de scott\n",
    "def nclass_scott(x):\n",
    "    h=3.5*(np.var(x,ddof=1)**.5)*len(x)**(-.3333)\n",
    "    intervals=m.ceil((max(x)-min(x))/h)\n",
    "    return int(intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion para discretizar todas las colunmnas de un dataframe\n",
    "def disc_ew(df,out):\n",
    "    name=df.columns.tolist()\n",
    "    disc=pd.DataFrame()\n",
    "    for name in df.columns.tolist():\n",
    "        k=nclass_scott(df[name])\n",
    "        disc[name]=disc_col_ew(df,name,k,out)\n",
    "    return disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discretizando las columnas de la matriz predictora X de diabetes\n",
    "diab_disc=disc_ew(X,out=\"num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 105.387  120.206    2.87    10.086   59.232   42.746   62.639  115.924]\n",
      "[[ 4 11  6]\n",
      " [ 0  6  2]\n",
      " [ 6 14  2]\n",
      " ..., \n",
      " [ 3  9  1]\n",
      " [ 0 10  5]\n",
      " [ 0  7  0]]\n"
     ]
    }
   ],
   "source": [
    "y1=y.as_matrix()\n",
    "X1=diab_disc.as_matrix()\n",
    "# feature extraction\n",
    "test = SelectKBest(score_func=chi2, k=3)\n",
    "fit = test.fit(X1, y1)\n",
    "# summarize scores\n",
    "np.set_printoptions(precision=3)\n",
    "print(fit.scores_)\n",
    "features= fit.transform(X1)\n",
    "# Imprime los datos de las tres mejores features\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comentario: Las tres mejores variables con la prueba de Chi-square son plas(2), age(8) y preg(1) por tener el Chi-Square mas alto.\n",
    "\n",
    "II-Usando la prueba de estadistica de F para comparar dos o mas grupos\n",
    "\n",
    "Se puede usar la libreria sciki-learn o la libreria de la ASU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II-Usando la prueba de estadistica de F para comparar dos o mas grupos\n",
    "\n",
    "#### Se puede usar la libreria sciki-learn o la libreria de la ASU\n",
    "#### Seleccion  de Features usando los p-values de la F-test como score\n",
    "#### Aqui usamos scikit-learn y se selecciona el 30% de deatures con el mas alto score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.221  1.     0.027  0.034  0.084  0.378  0.14   0.253]\n",
      "[[ 148.    33.6   50. ]\n",
      " [  85.    26.6   31. ]\n",
      " [ 183.    23.3   32. ]\n",
      " ..., \n",
      " [ 121.    26.2   30. ]\n",
      " [ 126.    30.1   47. ]\n",
      " [  93.    30.4   23. ]]\n"
     ]
    }
   ],
   "source": [
    "selector = SelectPercentile(f_classif, percentile=30)\n",
    "fit=selector.fit(X, y)\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "scores /= scores.max()\n",
    "print(scores)\n",
    "features= fit.transform(X)\n",
    "# Imprime los datos de las tres mejores features\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comentario: Las tres, mejores variables con la prueba de F son plas,mass y age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  25.624,  178.853,    1.976,    2.186,    6.758,   68.07 ,\n",
      "         15.168,   30.702]), array([1, 5, 7, 0, 6, 4, 3, 2], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "#Usando la libreria Feature selection de la ASU\n",
    "features, labels = X.values, data['class'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels)\n",
    "from skfeature.function.statistical_based import f_score\n",
    "scoref = f_score.f_score(X_train, y_train)\n",
    "idx = f_score.feature_ranking(scoref)\n",
    "print(scoref,idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comentario: las tres variables mas importantes con la prueba de F son: plas(2),mass(6) y age (8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III- Usando Mutual Information (Entropia)\n",
    "\n",
    "Libreria scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.21   1.     0.     0.164  0.386  0.643  0.135  0.382]\n"
     ]
    }
   ],
   "source": [
    "# Univariate feature selection with Mutual Information\n",
    "scores = mutual_info_classif(X,y)\n",
    "scores /= scores.max()\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Comentario: Las tres variables usando el criterio de Mutual Information son: plas(2), mass(6) y age(8)\n",
    "\n",
    "### IV-Usando ReliefF de la libreria skrebate\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrebate import ReliefF\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df=data.drop('class',axis=1)\n",
    "#Normalizando las predictoras\n",
    "df_norm=(df - df.min()) / (df.max() - df.min())\n",
    "features, labels = df_norm.values, data['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('preg', 38.928571428571438)\n",
      "('plas', 77.454773869346795)\n",
      "('pres', 12.348360655737721)\n",
      "('skin', 55.033333333333324)\n",
      "('test', 18.517473118279579)\n",
      "('mass', 47.304769001490286)\n",
      "('pedi', 19.15992892047981)\n",
      "('age', 48.205882352941138)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels)\n",
    "\n",
    "fs = ReliefF(n_neighbors=10)\n",
    "fs.fit(X_train, y_train)\n",
    "\n",
    "for feature_name, feature_score in zip(df.columns,fs.feature_importances_):\n",
    "    print (feature_name, feature_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comentario: las tres variables mas importantes con el ReliefF son: plas,mass y skin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  4.786,  12.749,   4.308,  11.993,   1.77 ,  10.177,   2.811,\n",
      "         7.894]), array([1, 3, 5, 7, 0, 2, 6, 4], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "#Usando la libreria feature selection de la ASU\n",
    "from skfeature.function.similarity_based import reliefF\n",
    "score_relief=reliefF.reliefF(X_train,y_train)\n",
    "feat=reliefF.feature_ranking(score_relief)\n",
    "print(score_relief,feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Comentario: las tres variables mas importantes con el RelieF son: plas, mass y skin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature scores for best three features (scored individually):\n",
      "0.036 plas\n",
      "0.026 age\n",
      "0.015 mass\n"
     ]
    }
   ],
   "source": [
    "#Usando el Relief de Orange\n",
    "import Orange\n",
    "df = Orange.data.Table(\"diabetes\")\n",
    "\n",
    "def print_best_3(ma):\n",
    "    for m in ma[:3]:\n",
    "        print \"%5.3f %s\" % (m[1], m[0])\n",
    "\n",
    "print 'Feature scores for best three features (scored individually):'\n",
    "#ReliefF usando 10 vecinos mas cercanos y  una muestrd m-100 para updating de los pesos\n",
    "meas = Orange.feature.scoring.Relief(k=10, m=100)\n",
    "mr = [ (a.name, meas(a, df)) for a in df.domain.attributes]\n",
    "mr.sort(key=lambda x: -x[1]) #sort decreasingly by the score\n",
    "print_best_3(mr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando el reliefF de la ASU\n",
    "#load data\n",
    "url= \"http://academic.uprm.edu/eacuna/bupa.dat\"\n",
    "names = ['mcv', 'alkphos', 'sgpt', 'aspar', 'gammagt', 'drinks', 'class']\n",
    "data = pd.read_table(url, names=names,header=None)\n",
    "y=data['class']\n",
    "X=data.iloc[:,0:6]\n",
    "y1=y.as_matrix()\n",
    "X1=X.as_matrix()\n",
    "features, labels = X.values, data['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   9.8,   11.8,  258.8,  100.6,  -26. ,   51.6]), array([2, 3, 5, 1, 0, 4], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels)\n",
    "score_relief=reliefF.reliefF(X_train,y_train)\n",
    "feat=reliefF.feature_ranking(score_relief)\n",
    "print(score_relief,feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Rielief de ASU recomienda sgpt,aspar y drinks como las mejoras predictoras(***)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mcv', 6.8999999999999924)\n",
      "('alkphos', -2.6608695652173888)\n",
      "('sgpt', 5.5794701986754962)\n",
      "('aspar', 1.8972602739726028)\n",
      "('gammagt', 6.7705479452054806)\n",
      "('drinks', 6.1250000000000053)\n"
     ]
    }
   ],
   "source": [
    "fs = ReliefF(n_neighbors=10)\n",
    "fs.fit(X_train, y_train)\n",
    "\n",
    "for feature_name, feature_score in zip(data.columns,fs.feature_importances_):\n",
    "    print (feature_name, feature_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El relielf de skrebate recomienda gammagt, sgpt y drinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='http://academic.uprm.edu/eacuna/landsat.txt'\n",
    "data = pd.read_table(url, header=None,delim_whitespace=True)\n",
    "y=data.iloc[:,36]\n",
    "X=data.iloc[:,0:36]\n",
    "y1=y.as_matrix()\n",
    "X1=X.as_matrix()\n",
    "features, labels = X.values, y.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  941029.049,  1235293.399,   922072.516,  1113361.246,\n",
      "         892324.03 ,  1191842.818,   853138.339,  1004128.13 ,\n",
      "         995782.317,  1357151.35 ,   861505.329,  1171701.683,\n",
      "         973918.465,  1239353.523,   886857.916,  1069429.199,\n",
      "         964050.236,  1292473.082,   843190.446,  1000798.569,\n",
      "        1033231.163,  1445319.275,   794793.958,  1072131.319,\n",
      "         975229.727,  1280813.083,   861520.985,  1039042.356,\n",
      "         926222.435,  1276662.863,   792328.425,   973153.352,\n",
      "         983277.312,  1395561.086,   850211.81 ,  1102658.697]), array([21, 33,  9, 17, 25, 29, 13,  1,  5, 11,  3, 35, 23, 15, 27, 20,  7,\n",
      "       19,  8, 32, 24, 12, 31, 16,  0, 28,  2,  4, 14, 26, 10,  6, 34, 18,\n",
      "       22, 30], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "#usando Relief de la ASU\n",
    "score_relief=reliefF.reliefF(X_train,y_train)\n",
    "feat=reliefF.feature_ranking(score_relief)\n",
    "print(score_relief,feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature scores for best three features (scored individually):\n",
      "0.113 a17\n",
      "0.109 a13\n",
      "0.109 a21\n",
      "0.108 a1\n",
      "0.106 a33\n",
      "0.102 a9\n",
      "0.100 a25\n",
      "0.097 a29\n",
      "0.095 a5\n",
      "0.095 a14\n"
     ]
    }
   ],
   "source": [
    "#Usando el Relief de Orange\n",
    "import Orange\n",
    "df = Orange.data.Table(\"landsat\")\n",
    "\n",
    "def print_best_3(ma):\n",
    "    for m in ma[:10]:\n",
    "        print \"%5.3f %s\" % (m[1], m[0])\n",
    "\n",
    "print 'Feature scores for best three features (scored individually):'\n",
    "#ReliefF usando 10 vecinos mas cercanos y  una muestrd m-100 para updating de los pesos\n",
    "meas = Orange.feature.scoring.Relief(k=1, m=100)\n",
    "mr = [ (a.name, meas(a, df)) for a in df.domain.attributes]\n",
    "mr.sort(key=lambda x: -x[1]) #sort decreasingly by the score\n",
    "print_best_3(mr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
